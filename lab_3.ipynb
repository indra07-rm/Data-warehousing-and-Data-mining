{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1u4WRVtrYxlZL-Cm6K0BchXlrfJ-JLc3f",
      "authorship_tag": "ABX9TyMPTiw0011llIQJr/hxPXER",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indra07-rm/Data-warehousing-and-Data-mining/blob/main/lab_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5BupvTRdPk6",
        "outputId": "830e0d18-f738-404a-9997-2038cca998d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree:\n",
            "[Age = Youth]\n",
            "  [Student = Yes]\n",
            "    ➤ Buy\n",
            "  [Student = No]\n",
            "    [Credit_Rating = Excellent]\n",
            "      ➤ No\n",
            "    [Credit_Rating = Fair]\n",
            "      ➤ Buy\n",
            "[Age = Middle_Aged]\n",
            "  [Income = Low]\n",
            "    [Credit_Rating = Excellent]\n",
            "      ➤ No\n",
            "    [Credit_Rating = Fair]\n",
            "      [Student = Yes]\n",
            "        ➤ Buy\n",
            "  [Income = Medium]\n",
            "    ➤ No\n",
            "  [Income = High]\n",
            "    ➤ No\n",
            "[Age = Senior]\n",
            "  [Credit_Rating = Fair]\n",
            "    ➤ No\n",
            "  [Credit_Rating = Excellent]\n",
            "    [Income = Low]\n",
            "      ➤ Buy\n",
            "    [Income = High]\n",
            "      [Student = No]\n",
            "        ➤ Buy\n",
            "    [Income = Medium]\n",
            "      ➤ Buy\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "def load_csv(file_path):\n",
        "    return pd.read_csv(file_path)\n",
        "\n",
        "def entropy(data, target_attr):\n",
        "    values = data[target_attr]\n",
        "    freq = Counter(values)\n",
        "    ent = 0.0\n",
        "    for f in freq.values():\n",
        "        p = f / len(data)\n",
        "        ent -= p * math.log2(p)\n",
        "    return ent\n",
        "\n",
        "def info_gain(data, attr, target_attr):\n",
        "    total_entropy = entropy(data, target_attr)\n",
        "    vals = data[attr].unique()\n",
        "    weighted_entropy = 0.0\n",
        "    for val in vals:\n",
        "        subset = data[data[attr] == val]\n",
        "        weight = len(subset) / len(data)\n",
        "        weighted_entropy += weight * entropy(subset, target_attr)\n",
        "    return total_entropy - weighted_entropy\n",
        "\n",
        "def choose_best_attr(data, attributes, target_attr):\n",
        "    best_gain = -1\n",
        "    best_attr = None\n",
        "    for attr in attributes:\n",
        "        gain = info_gain(data, attr, target_attr)\n",
        "        if gain > best_gain:\n",
        "            best_gain = gain\n",
        "            best_attr = attr\n",
        "    return best_attr\n",
        "\n",
        "def majority_class(data, target_attr):\n",
        "    return data[target_attr].mode()[0]\n",
        "\n",
        "def id3(data, attributes, target_attr):\n",
        "    unique_classes = data[target_attr].unique()\n",
        "\n",
        "    # Base case 1: if all examples are of same class\n",
        "    if len(unique_classes) == 1:\n",
        "        return unique_classes[0]\n",
        "\n",
        "    # Base case 2: no more attributes\n",
        "    if len(attributes) == 0:\n",
        "        return majority_class(data, target_attr)\n",
        "\n",
        "    # Choose the best attribute\n",
        "    best_attr = choose_best_attr(data, attributes, target_attr)\n",
        "    tree = {best_attr: {}}\n",
        "\n",
        "    for val in data[best_attr].unique():\n",
        "        subset = data[data[best_attr] == val]\n",
        "        if subset.empty:\n",
        "            tree[best_attr][val] = majority_class(data, target_attr)\n",
        "        else:\n",
        "            new_attrs = [attr for attr in attributes if attr != best_attr]\n",
        "            tree[best_attr][val] = id3(subset, new_attrs, target_attr)\n",
        "\n",
        "    return tree\n",
        "def print_tree(tree, indent=\"\"):\n",
        "    if not isinstance(tree, dict):\n",
        "        print(indent + \"➤ \" + str(tree))\n",
        "        return\n",
        "    for attr, branches in tree.items():\n",
        "        for val, subtree in branches.items():\n",
        "            print(f\"{indent}[{attr} = {val}]\")\n",
        "            print_tree(subtree, indent + \"  \")\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    # Path to your CSV\n",
        "    file_path = \"/content/drive/MyDrive/data mining /laptop_buy_data.csv\"\n",
        "    df = load_csv(file_path)\n",
        "\n",
        "    target_attr = 'Class'  # Change if your label column is different\n",
        "    attributes = [col for col in df.columns if col != target_attr]\n",
        "\n",
        "    # Build and print the decision tree\n",
        "    tree = id3(df, attributes, target_attr)\n",
        "    print(\"Decision Tree:\")\n",
        "    print_tree(tree)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "class NaiveBayesClassifier:\n",
        "    def __init__(self):\n",
        "        self.class_probs = {}\n",
        "        self.cond_probs = defaultdict(dict)\n",
        "\n",
        "    def fit(self, data, target_attr):\n",
        "        total_count = len(data)\n",
        "        self.attributes = [col for col in data.columns if col != target_attr]\n",
        "\n",
        "        class_counts = data[target_attr].value_counts()\n",
        "        self.class_probs = {cls: count / total_count for cls, count in class_counts.items()}\n",
        "\n",
        "        for attr in self.attributes:\n",
        "            for cls in class_counts.index:\n",
        "                subset = data[data[target_attr] == cls]\n",
        "                value_counts = subset[attr].value_counts()\n",
        "                total_cls = len(subset)\n",
        "                for val in data[attr].unique():\n",
        "                    # Apply Laplace smoothing\n",
        "                    count = value_counts.get(val, 0)\n",
        "                    prob = (count + 1) / (total_cls + len(data[attr].unique()))\n",
        "                    self.cond_probs[(attr, val)][cls] = prob\n",
        "\n",
        "    def predict(self, instance):\n",
        "        posteriors = {}\n",
        "        for cls in self.class_probs:\n",
        "            prob = self.class_probs[cls]\n",
        "            for attr in self.attributes:\n",
        "                val = instance.get(attr)\n",
        "                prob *= self.cond_probs.get((attr, val), {}).get(cls, 1e-6)  # handle unseen values\n",
        "            posteriors[cls] = prob\n",
        "        return max(posteriors, key=posteriors.get)\n",
        "\n",
        "    def predict_all(self, data):\n",
        "        return [self.predict(row) for _, row in data.iterrows()]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/data mining /laptop_buy_data.csv\")\n",
        "\n",
        "    # Instantiate and train the model\n",
        "    nb = NaiveBayesClassifier()\n",
        "    nb.fit(df, target_attr='Class')\n",
        "\n",
        "    # Test prediction\n",
        "    test_instance = {\n",
        "        'Age': 'Youth',\n",
        "        'Income': 'Low',\n",
        "        'Student': 'No',\n",
        "        'Credit_Rating': 'Excellent'\n",
        "    }\n",
        "\n",
        "    prediction = nb.predict(test_instance)\n",
        "    print(\"Prediction for test instance:\", prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc7RVT4ceHJv",
        "outputId": "1bc3a26a-483e-4958-deba-907f6b91b5aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for test instance: Buy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "X = np.array([\n",
        "    [-1, -1],\n",
        "    [-1,  1],\n",
        "    [ 1, -1],\n",
        "    [ 1,  1]\n",
        "])\n",
        "\n",
        "y = np.array([[-1], [1], [1], [-1]])\n",
        "\n",
        "y_scaled = (y + 1) / 2\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "input_size = 2\n",
        "hidden_size = 2\n",
        "output_size = 1\n",
        "\n",
        "\n",
        "W1 = 2 * np.random.rand(input_size, hidden_size) - 1\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "\n",
        "W2 = 2 * np.random.rand(hidden_size, output_size) - 1\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "epochs = 10000\n",
        "learning_rate = 0.1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    error = y_scaled - a2\n",
        "    d_output = error * sigmoid_derivative(a2)\n",
        "\n",
        "    d_hidden = d_output.dot(W2.T) * sigmoid_derivative(a1)\n",
        "\n",
        "    W2 += a1.T.dot(d_output) * learning_rate\n",
        "    b2 += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    W1 += X.T.dot(d_hidden) * learning_rate\n",
        "    b1 += np.sum(d_hidden, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "\n",
        "output = sigmoid(np.dot(sigmoid(np.dot(X, W1) + b1), W2) + b2)\n",
        "predicted = (output > 0.5).astype(int)\n",
        "true_label = (y_scaled > 0.5).astype(int)\n",
        "\n",
        "print(\"Predicted outputs (0 or 1):\\n\", predicted)\n",
        "print(\"Actual outputs:\\n\", true_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgzVO4JmeQ9x",
        "outputId": "d81c1dfa-c462-4eaf-b1e7-aa3882dc2a69"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted outputs (0 or 1):\n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n",
            "Actual outputs:\n",
            " [[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cqWw_5NXeWrp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}